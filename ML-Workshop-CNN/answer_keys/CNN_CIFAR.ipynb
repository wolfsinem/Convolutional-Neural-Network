{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n<frozen importlib._bootstrap>:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.8\n<frozen importlib._bootstrap>:219: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 880, got 864\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.load_data import load_train, load_test"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "iFT4RPYQkCap"
   },
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Een CNN is veel beter geschikt voor taken zoals foto herkenning en taal patronen. In tegenstelling tot een normaal NN heeft een CNN layers met nodes die niet allemaal aan elkaar verbonden zijn. \n",
    "\n",
    "Een heel basic CNN kan de volgende structuur hebben:\n",
    "\n",
    "\n",
    "We beginnen met een input layer. Deze input layer kan bijvoorbeeld een afbeelding als input nemen. Vervolgens hebben we de Convolution Layer. Daarna hebben we een Pooling Layer. Elk van deze layers krijgt verder op in het Notebook een verdere uitleg. \n",
    "\n",
    "Wat opvalt is dat we een Fully Connected Layer hebben. Dit is uiteindelijk nodig voor de onze Output Layer. \n",
    "\n",
    "## Voordelen\n",
    "* CNN heeft niet het probleem dat je heel snel kan eindigen met 150+ miljoen weights; een CNN is dus makkelijker te trainen dan een NN om deze reden\n",
    "* Voor een CNN maakt het niet uit of een hond linksboven of rechtsonder staat in de foto. Een CNN focused niet op iedere pixel maar kijkt eerder naar pixels in de context van hun buren om zo een afbeelding te herkennen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "uBQzKWVFl36b"
   },
   "outputs": [],
   "source": [
    "### Convolution Layer\n",
    "\n",
    "Net als in elke andere laag ontvangt een convolutional layer een bepaalde input, transformeert het de input op een bepaalde manier en stuurt het resultaat van de transformatie door naar de volgende laag.  \n",
    "\n",
    "Convolution lagen bestaan uit een set van leerbare filters (ook wel *kernels* genoemd). Iedere filter is in de ruimtelijke zin klein (qua hoogte en breedte), maar strekt zich uit over de volledige diepte van de input.  \n",
    "\n",
    "Tijdens de forward propagation glijdt elke filter over de hoogte en breedte van de input en berekend de dot product tu\n",
    "\n",
    "<img src=\"src/convolution_schematic.gif\" width=\"100\" align=\"center\">\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "De convolution layer maakt gebruik bepaalde filters die over de afbeelding ‘convolven’ (ruimtelijk over de afbeelding glijden terwijl het dot products  "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN bouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het importeren en bewerken van de data \n",
    "train_images, train_labels = load_train()\n",
    "test_images, test_labels = load_test()\n",
    "\n",
    "# Normalizeren van de images\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Reshapen van de images zodat ze de juiste dimensies hebben\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000, 28, 31, 1)\n(10000, 28, 31, 1)\n"
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onze CNN\n",
    "\n",
    "# Stap 1: bepaal hoeveel filters je wilt, hoe groot je filter size moet zijn (let op je filter size mag niet te groot zijn vergeleken met je images), en wat je pool size is. \n",
    "num_filters = 31 #remove val\n",
    "filter_size = 3 #remove val\n",
    "pool_size = 2 #remove val\n",
    "\n",
    "# Stap 2: maak het model. \n",
    "#    Conv2D parameters: num_filters, filter_size, input_shape=(x, y, z) \n",
    "#    MaxPooling2D parameters: pool_size=pool_size\n",
    "#    Flatten\n",
    "#    Dense parameters: aantal outputs, activation='softmax' \n",
    "#model = Sequential([])\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(num_filters, filter_size, input_shape = (28, 28, 1), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Conv2D(64, filter_size, activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Conv2D(64, filter_size, activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_4_input to have shape (28, 28, 1) but got array with shape (28, 31, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3a922a30c471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#    validation_data = test_images, to_categorial(test_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#model.fit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             first_x_value, batch_size, self._distribution_strategy)\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m     x, y, sample_weights = self._standardize_user_data(\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    989\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0m\u001b[1;32m    992\u001b[0m                                                      class_weight, batch_size)\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Standardize the inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m     x = training_utils.standardize_input_data(\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mfeed_input_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mref_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mref_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    330\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_4_input to have shape (28, 28, 1) but got array with shape (28, 31, 1)"
     ]
    }
   ],
   "source": [
    "# Stap 3: het compilen van het model. \n",
    "# model.compile parameters: 'adam', loss='categorial_crossentropy', metrics=['accuracy']\n",
    "#model.compile()\n",
    "model.compile(\n",
    "    'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "# Stap 4: fit het model. \n",
    "#    Data om op te trainen: train_images, to_categorial(train_labels)\n",
    "#    epochs = 3\n",
    "#    validation_data = test_images, to_categorial(test_labels)\n",
    "#model.fit()\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 5: evalueer het model\n",
    "test_loss, test_acc = model.evaluate(test_images,  to_categorical(test_labels), verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pS8vERMeHh8j"
   },
   "outputs": [],
   "source": [
    "# Stap 6: extra layer(s). Wat gebeurt er als je een extra Conv Layer toevoegd aan je model? \n",
    "#    Voeg een extra layer(s) toe en train het model opnieuw. \n",
    "# Stap 7: parameters. Wat gebeurt er bijvoorbeeld als je geen softmax gebruikt maar een andere activatie? \n",
    "#    Pas op z'n minst 1 parameter aan en train je model opnieuw. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Data inladen\n",
    "(train_images10, train_labels10), (test_images10, test_labels10) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalizeren\n",
    "train_images10, test_images10 = train_images10 / 255.0, test_images10 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cif = Sequential([\n",
    "    Conv2D(32, filter_size, input_shape = (32, 32, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Conv2D(64, filter_size, activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Conv2D(64, filter_size, activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_cif.compile(\n",
    "    'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cif.fit(\n",
    "  train_images10,\n",
    "  to_categorical(train_labels10),\n",
    "  epochs=10,\n",
    "  validation_data=(test_images10, to_categorical(test_labels10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_cif.evaluate(test_images10,  to_categorical(test_labels10), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.15-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}